{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions and load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 10:19:54.881821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 10:19:54.881880: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 10:19:54.881913: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 10:19:54.888493: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import Bio.SeqIO as SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout, Bidirectional, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.CNN_utils import remove_N, onehote\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    # Convert tensors to NumPy arrays for processing\n",
    "    y_true = tf.make_ndarray(y_true)\n",
    "    y_pred = tf.make_ndarray(y_pred)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion = tf.math.confusion_matrix(y_true, y_pred, num_classes=2)\n",
    "\n",
    "    # Calculate sensitivity (true positive rate) for each class\n",
    "    tp = confusion[1, 1]\n",
    "    fn = confusion[1, 0]\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    # Calculate the balanced accuracy as the average sensitivity\n",
    "    balanced_acc = sensitivity\n",
    "\n",
    "    return balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=3000\n",
    "MIN_LEN=0\n",
    "n_classes = 15\n",
    "LTRs = [rec for rec in SeqIO.parse(\"train_LTRs.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN+500 and len(rec.seq) > MIN_LEN]\n",
    "n_sequences = len(LTRs)\n",
    "\n",
    "generated, genomic, markov = int(n_sequences*0.2), int(n_sequences*0.5), int(n_sequences*0.3)\n",
    "\n",
    "d = pd.DataFrame({'sequence':[str(rec.seq) for rec in LTRs], 'label':[rec.description.split(\" \")[4] for rec in LTRs]})\n",
    "\n",
    "d = d[~d['label'].str.contains(\"copia\")]\n",
    "d = d[d[\"label\"].isin(d[\"label\"].value_counts()[:n_classes].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/134878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134878/134878 [00:28<00:00, 4701.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Encode labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(d['label'])\n",
    "pickle.dump(label_encoder, open(\"label_encoder.b\", \"wb\"))\n",
    "\n",
    "sequences = [onehote(remove_N(seq)) for seq in tqdm.tqdm(d[\"sequence\"])]\n",
    "\n",
    "# Split into train and test\n",
    "paddedDNA = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"pre\", maxlen=MAX_LEN)\n",
    "trainX, valX, trainY, valY = train_test_split(paddedDNA, encoded_labels, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_weights = class_weight.compute_class_weight( class_weight='balanced', classes=np.unique(encoded_labels), y=encoded_labels)\n",
    "weights = {c:w for c, w in zip(np.unique(encoded_labels), label_weights)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code for short sequence training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1897/1897 [==============================] - 64s 33ms/step - loss: 2.2684 - sparse_categorical_accuracy: 0.2832 - weighted_sparse_categorical_accuracy: 0.2631 - val_loss: 1.8997 - val_sparse_categorical_accuracy: 0.4132 - val_weighted_sparse_categorical_accuracy: 0.4132\n",
      "Epoch 2/15\n",
      "1897/1897 [==============================] - 61s 32ms/step - loss: 1.6792 - sparse_categorical_accuracy: 0.4813 - weighted_sparse_categorical_accuracy: 0.4728 - val_loss: 1.5244 - val_sparse_categorical_accuracy: 0.5380 - val_weighted_sparse_categorical_accuracy: 0.5380\n",
      "Epoch 3/15\n",
      "1897/1897 [==============================] - 61s 32ms/step - loss: 1.3583 - sparse_categorical_accuracy: 0.5764 - weighted_sparse_categorical_accuracy: 0.5847 - val_loss: 1.2869 - val_sparse_categorical_accuracy: 0.6055 - val_weighted_sparse_categorical_accuracy: 0.6055\n",
      "Epoch 4/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 1.1761 - sparse_categorical_accuracy: 0.6312 - weighted_sparse_categorical_accuracy: 0.6431 - val_loss: 1.1932 - val_sparse_categorical_accuracy: 0.6343 - val_weighted_sparse_categorical_accuracy: 0.6343\n",
      "Epoch 5/15\n",
      "1897/1897 [==============================] - 61s 32ms/step - loss: 1.0561 - sparse_categorical_accuracy: 0.6660 - weighted_sparse_categorical_accuracy: 0.6826 - val_loss: 1.1017 - val_sparse_categorical_accuracy: 0.6632 - val_weighted_sparse_categorical_accuracy: 0.6632\n",
      "Epoch 6/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.9625 - sparse_categorical_accuracy: 0.6924 - weighted_sparse_categorical_accuracy: 0.7125 - val_loss: 1.0680 - val_sparse_categorical_accuracy: 0.6802 - val_weighted_sparse_categorical_accuracy: 0.6802\n",
      "Epoch 7/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.8901 - sparse_categorical_accuracy: 0.7128 - weighted_sparse_categorical_accuracy: 0.7350 - val_loss: 1.0143 - val_sparse_categorical_accuracy: 0.6974 - val_weighted_sparse_categorical_accuracy: 0.6974\n",
      "Epoch 8/15\n",
      "1897/1897 [==============================] - 61s 32ms/step - loss: 0.8307 - sparse_categorical_accuracy: 0.7284 - weighted_sparse_categorical_accuracy: 0.7541 - val_loss: 0.9415 - val_sparse_categorical_accuracy: 0.7179 - val_weighted_sparse_categorical_accuracy: 0.7179\n",
      "Epoch 9/15\n",
      "1897/1897 [==============================] - 61s 32ms/step - loss: 0.7807 - sparse_categorical_accuracy: 0.7402 - weighted_sparse_categorical_accuracy: 0.7668 - val_loss: 0.9658 - val_sparse_categorical_accuracy: 0.7131 - val_weighted_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 10/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.7334 - sparse_categorical_accuracy: 0.7526 - weighted_sparse_categorical_accuracy: 0.7830 - val_loss: 0.9047 - val_sparse_categorical_accuracy: 0.7378 - val_weighted_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 11/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.7619 - weighted_sparse_categorical_accuracy: 0.7936 - val_loss: 0.8947 - val_sparse_categorical_accuracy: 0.7390 - val_weighted_sparse_categorical_accuracy: 0.7390\n",
      "Epoch 12/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.6600 - sparse_categorical_accuracy: 0.7704 - weighted_sparse_categorical_accuracy: 0.8033 - val_loss: 0.9231 - val_sparse_categorical_accuracy: 0.7299 - val_weighted_sparse_categorical_accuracy: 0.7299\n",
      "Epoch 13/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.7786 - weighted_sparse_categorical_accuracy: 0.8124 - val_loss: 0.9182 - val_sparse_categorical_accuracy: 0.7349 - val_weighted_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 14/15\n",
      "1897/1897 [==============================] - 60s 32ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.7860 - weighted_sparse_categorical_accuracy: 0.8217 - val_loss: 0.8952 - val_sparse_categorical_accuracy: 0.7394 - val_weighted_sparse_categorical_accuracy: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/xhorvat9/tf_CUDA/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv1D(filters=128, kernel_size=8, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "\n",
    "model2.add(LSTM(150))\n",
    "model2.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'], weighted_metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model2.fit(trainX, trainY, epochs=15, batch_size=64,verbose = 1,validation_data=(valX, valY), callbacks=[EarlyStopping(monitor='val_loss', patience=3)], class_weight=weights)\n",
    "\n",
    "model2.save(\"all_length_cnn_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
