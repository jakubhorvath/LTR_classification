{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions and load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:47:04.485071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 10:47:04.485158: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 10:47:04.485205: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 10:47:04.495570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import Bio.SeqIO as SeqIO\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout, Bidirectional, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import wandb\n",
    "from utils.CNN_utils import remove_N, onehote\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    # Convert tensors to NumPy arrays for processing\n",
    "    y_true = tf.make_ndarray(y_true)\n",
    "    y_pred = tf.make_ndarray(y_pred)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion = tf.math.confusion_matrix(y_true, y_pred, num_classes=2)\n",
    "\n",
    "    # Calculate sensitivity (true positive rate) for each class\n",
    "    tp = confusion[1, 1]\n",
    "    fn = confusion[1, 0]\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    # Calculate the balanced accuracy as the average sensitivity\n",
    "    balanced_acc = sensitivity\n",
    "\n",
    "    return balanced_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code for short sequence training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283064/283064 [02:13<00:00, 2121.83it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=3000\n",
    "MIN_LEN=0\n",
    "\n",
    "LTRs = [rec for rec in SeqIO.parse(\"train_LTRs.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "n_sequences = len(LTRs)\n",
    "\n",
    "non_LTRs = [rec for rec in SeqIO.parse(\"train_nonLTRs.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "\n",
    "sequences = [onehote(remove_N(str(rec.seq))) for rec in tqdm.tqdm(non_LTRs+LTRs)]\n",
    "labels = [0]*len(non_LTRs) + [1]*len(LTRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test\n",
    "paddedDNA = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"pre\", maxlen=MAX_LEN)\n",
    "trainX, valX, trainY, valY = train_test_split(paddedDNA, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3981/3981 [==============================] - 26s 6ms/step - loss: 0.5101 - binary_accuracy: 0.7404 - weighted_binary_accuracy: 0.7404 - val_loss: 0.4512 - val_binary_accuracy: 0.7772 - val_weighted_binary_accuracy: 0.7772\n",
      "Epoch 2/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.4195 - binary_accuracy: 0.7998 - weighted_binary_accuracy: 0.7998 - val_loss: 0.4097 - val_binary_accuracy: 0.8057 - val_weighted_binary_accuracy: 0.8057\n",
      "Epoch 3/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3878 - binary_accuracy: 0.8168 - weighted_binary_accuracy: 0.8168 - val_loss: 0.3978 - val_binary_accuracy: 0.8191 - val_weighted_binary_accuracy: 0.8191\n",
      "Epoch 4/15\n",
      "3981/3981 [==============================] - 32s 8ms/step - loss: 0.3645 - binary_accuracy: 0.8303 - weighted_binary_accuracy: 0.8303 - val_loss: 0.3793 - val_binary_accuracy: 0.8225 - val_weighted_binary_accuracy: 0.8225\n",
      "Epoch 5/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3450 - binary_accuracy: 0.8400 - weighted_binary_accuracy: 0.8400 - val_loss: 0.3847 - val_binary_accuracy: 0.8216 - val_weighted_binary_accuracy: 0.8216\n",
      "Epoch 6/15\n",
      "3981/3981 [==============================] - 24s 6ms/step - loss: 0.3274 - binary_accuracy: 0.8495 - weighted_binary_accuracy: 0.8495 - val_loss: 0.3807 - val_binary_accuracy: 0.8227 - val_weighted_binary_accuracy: 0.8227\n",
      "Epoch 7/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3098 - binary_accuracy: 0.8581 - weighted_binary_accuracy: 0.8581 - val_loss: 0.3793 - val_binary_accuracy: 0.8224 - val_weighted_binary_accuracy: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f11be2694f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv1D(filters=32, kernel_size=16, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(units=256, activation='relu'))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'], weighted_metrics=[\"binary_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model2.fit(trainX, np.array(trainY).reshape(-1, 1), epochs=15, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY).reshape(-1, 1)), callbacks=[EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/xhorvat9/tf_CUDA/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"all_length_cnn_lstm_for_SHAP.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
