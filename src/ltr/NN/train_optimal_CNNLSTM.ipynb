{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions and load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 10:47:04.485071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 10:47:04.485158: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 10:47:04.485205: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 10:47:04.495570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import Bio.SeqIO as SeqIO\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout, Bidirectional, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import wandb\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    # Convert tensors to NumPy arrays for processing\n",
    "    y_true = tf.make_ndarray(y_true)\n",
    "    y_pred = tf.make_ndarray(y_pred)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    confusion = tf.math.confusion_matrix(y_true, y_pred, num_classes=2)\n",
    "\n",
    "    # Calculate sensitivity (true positive rate) for each class\n",
    "    tp = confusion[1, 1]\n",
    "    fn = confusion[1, 0]\n",
    "    sensitivity = tp / (tp + fn)\n",
    "\n",
    "    # Calculate the balanced accuracy as the average sensitivity\n",
    "    balanced_acc = sensitivity\n",
    "\n",
    "    return balanced_acc\n",
    "\n",
    "def remove_N(seq):\n",
    "    \"\"\"\n",
    "    Remove Ns from sequence\n",
    "    \"\"\"\n",
    "    return seq.upper().replace(\"N\", \"\")\n",
    "\n",
    "def onehote(seq):\n",
    "    \"\"\"\n",
    "    One Hot encoding function\n",
    "    \"\"\"\n",
    "    seq2=list()\n",
    "    mapping = {\"A\":[1., 0., 0., 0.], \"C\": [0., 1., 0., 0.], \"G\": [0, 0., 1., 0.], \"T\":[0., 0., 0., 1.], \"N\":[0., 0., 0., 0.]}\n",
    "    for i in seq:\n",
    "      seq2.append(mapping[i]  if i in mapping.keys() else [0., 0., 0., 0.]) \n",
    "    return np.array(seq2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code for short sequence training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283064/283064 [02:13<00:00, 2121.83it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=3000\n",
    "MIN_LEN=0\n",
    "\n",
    "LTRs = [rec for rec in SeqIO.parse(\"/data/xhorvat9/ltr_bert/FASTA_files/train_LTRs.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "n_sequences = len(LTRs)\n",
    "\n",
    "generated, genomic, markov = int(n_sequences*0.2), int(n_sequences*0.5), int(n_sequences*0.3)\n",
    "\n",
    "genomic_non_LTRs = [rec for rec in SeqIO.parse(\"/data/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_genomic_extracts.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if genomic < len(genomic_non_LTRs):\n",
    "    genomic_non_LTRs = random.sample(genomic_non_LTRs, genomic)\n",
    "generated_non_LTRs = [rec for rec in SeqIO.parse(\"/data/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_generated.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if generated < len(generated_non_LTRs):\n",
    "    generated_non_LTRs = random.sample(generated_non_LTRs, generated)\n",
    "markov_non_LTRs = [rec for rec in SeqIO.parse(\"/data/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_markovChain.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if markov < len(markov_non_LTRs):\n",
    "    markov_non_LTRs = random.sample(markov_non_LTRs, markov)\n",
    "non_LTRs = genomic_non_LTRs + generated_non_LTRs + markov_non_LTRs\n",
    "# test for sequences below 500\n",
    "sequences = [onehote(remove_N(str(rec.seq))) for rec in tqdm.tqdm(non_LTRs+LTRs)]\n",
    "#sequences = [onehote(str(rec.seq)) for rec in tqdm.tqdm(LTRs)] + [onehote(str(rec.seq)) for rec in tqdm.tqdm(non_LTRs)]\n",
    "labels = [0]*len(non_LTRs) + [1]*len(LTRs)\n",
    "\n",
    "# One-hot encode the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test\n",
    "paddedDNA = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"pre\", maxlen=MAX_LEN)\n",
    "trainX, valX, trainY, valY = train_test_split(paddedDNA, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254757, 3000, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254757, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainY).reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3981/3981 [==============================] - 26s 6ms/step - loss: 0.5101 - binary_accuracy: 0.7404 - weighted_binary_accuracy: 0.7404 - val_loss: 0.4512 - val_binary_accuracy: 0.7772 - val_weighted_binary_accuracy: 0.7772\n",
      "Epoch 2/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.4195 - binary_accuracy: 0.7998 - weighted_binary_accuracy: 0.7998 - val_loss: 0.4097 - val_binary_accuracy: 0.8057 - val_weighted_binary_accuracy: 0.8057\n",
      "Epoch 3/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3878 - binary_accuracy: 0.8168 - weighted_binary_accuracy: 0.8168 - val_loss: 0.3978 - val_binary_accuracy: 0.8191 - val_weighted_binary_accuracy: 0.8191\n",
      "Epoch 4/15\n",
      "3981/3981 [==============================] - 32s 8ms/step - loss: 0.3645 - binary_accuracy: 0.8303 - weighted_binary_accuracy: 0.8303 - val_loss: 0.3793 - val_binary_accuracy: 0.8225 - val_weighted_binary_accuracy: 0.8225\n",
      "Epoch 5/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3450 - binary_accuracy: 0.8400 - weighted_binary_accuracy: 0.8400 - val_loss: 0.3847 - val_binary_accuracy: 0.8216 - val_weighted_binary_accuracy: 0.8216\n",
      "Epoch 6/15\n",
      "3981/3981 [==============================] - 24s 6ms/step - loss: 0.3274 - binary_accuracy: 0.8495 - weighted_binary_accuracy: 0.8495 - val_loss: 0.3807 - val_binary_accuracy: 0.8227 - val_weighted_binary_accuracy: 0.8227\n",
      "Epoch 7/15\n",
      "3981/3981 [==============================] - 23s 6ms/step - loss: 0.3098 - binary_accuracy: 0.8581 - weighted_binary_accuracy: 0.8581 - val_loss: 0.3793 - val_binary_accuracy: 0.8224 - val_weighted_binary_accuracy: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f11be2694f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv1D(filters=32, kernel_size=16, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(units=256, activation='relu'))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'], weighted_metrics=[\"binary_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model2.fit(trainX, np.array(trainY).reshape(-1, 1), epochs=15, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY).reshape(-1, 1)), callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/xhorvat9/tf_CUDA/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"all_length_cnn_lstm_for_SHAP.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283064/283064 [00:56<00:00, 5052.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3760/3760 [==============================] - 149s 39ms/step - loss: 0.5946 - binary_accuracy: 0.6621 - weighted_binary_accuracy: 0.6621 - val_loss: 0.5965 - val_binary_accuracy: 0.6749 - val_weighted_binary_accuracy: 0.6749\n",
      "Epoch 2/15\n",
      "3760/3760 [==============================] - 147s 39ms/step - loss: 0.4718 - binary_accuracy: 0.7635 - weighted_binary_accuracy: 0.7635 - val_loss: 0.4557 - val_binary_accuracy: 0.7820 - val_weighted_binary_accuracy: 0.7820\n",
      "Epoch 3/15\n",
      "3760/3760 [==============================] - 150s 40ms/step - loss: 0.4156 - binary_accuracy: 0.7999 - weighted_binary_accuracy: 0.7999 - val_loss: 0.4031 - val_binary_accuracy: 0.8076 - val_weighted_binary_accuracy: 0.8076\n",
      "Epoch 4/15\n",
      "3760/3760 [==============================] - 151s 40ms/step - loss: 0.3896 - binary_accuracy: 0.8157 - weighted_binary_accuracy: 0.8157 - val_loss: 0.3996 - val_binary_accuracy: 0.8123 - val_weighted_binary_accuracy: 0.8123\n",
      "Epoch 5/15\n",
      "3760/3760 [==============================] - 153s 41ms/step - loss: 0.3698 - binary_accuracy: 0.8263 - weighted_binary_accuracy: 0.8263 - val_loss: 0.3779 - val_binary_accuracy: 0.8225 - val_weighted_binary_accuracy: 0.8225\n",
      "Epoch 6/15\n",
      "3760/3760 [==============================] - 148s 39ms/step - loss: 0.3578 - binary_accuracy: 0.8341 - weighted_binary_accuracy: 0.8341 - val_loss: 0.3641 - val_binary_accuracy: 0.8305 - val_weighted_binary_accuracy: 0.8305\n",
      "Epoch 7/15\n",
      "3760/3760 [==============================] - 149s 40ms/step - loss: 0.3452 - binary_accuracy: 0.8403 - weighted_binary_accuracy: 0.8403 - val_loss: 0.3635 - val_binary_accuracy: 0.8314 - val_weighted_binary_accuracy: 0.8314\n",
      "Epoch 8/15\n",
      "3760/3760 [==============================] - 153s 41ms/step - loss: 0.3386 - binary_accuracy: 0.8437 - weighted_binary_accuracy: 0.8437 - val_loss: 0.3639 - val_binary_accuracy: 0.8317 - val_weighted_binary_accuracy: 0.8317\n",
      "Epoch 9/15\n",
      "3760/3760 [==============================] - 147s 39ms/step - loss: 0.3333 - binary_accuracy: 0.8465 - weighted_binary_accuracy: 0.8465 - val_loss: 0.3556 - val_binary_accuracy: 0.8367 - val_weighted_binary_accuracy: 0.8367\n",
      "Epoch 10/15\n",
      "3760/3760 [==============================] - 151s 40ms/step - loss: 0.3297 - binary_accuracy: 0.8490 - weighted_binary_accuracy: 0.8490 - val_loss: 0.3524 - val_binary_accuracy: 0.8360 - val_weighted_binary_accuracy: 0.8360\n",
      "Epoch 11/15\n",
      "3760/3760 [==============================] - 149s 40ms/step - loss: 0.3271 - binary_accuracy: 0.8502 - weighted_binary_accuracy: 0.8502 - val_loss: 0.3631 - val_binary_accuracy: 0.8316 - val_weighted_binary_accuracy: 0.8316\n",
      "Epoch 12/15\n",
      "3760/3760 [==============================] - 147s 39ms/step - loss: 0.3246 - binary_accuracy: 0.8522 - weighted_binary_accuracy: 0.8522 - val_loss: 0.3347 - val_binary_accuracy: 0.8471 - val_weighted_binary_accuracy: 0.8471\n",
      "Epoch 13/15\n",
      "3760/3760 [==============================] - 150s 40ms/step - loss: 0.3199 - binary_accuracy: 0.8540 - weighted_binary_accuracy: 0.8540 - val_loss: 0.3470 - val_binary_accuracy: 0.8404 - val_weighted_binary_accuracy: 0.8404\n",
      "Epoch 14/15\n",
      "3760/3760 [==============================] - 149s 40ms/step - loss: 0.3134 - binary_accuracy: 0.8576 - weighted_binary_accuracy: 0.8576 - val_loss: 0.3328 - val_binary_accuracy: 0.8484 - val_weighted_binary_accuracy: 0.8484\n",
      "Epoch 15/15\n",
      "3760/3760 [==============================] - 149s 40ms/step - loss: 0.3073 - binary_accuracy: 0.8609 - weighted_binary_accuracy: 0.8609 - val_loss: 0.3312 - val_binary_accuracy: 0.8484 - val_weighted_binary_accuracy: 0.8484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5faf0180d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN=3000\n",
    "MIN_LEN=0\n",
    "\n",
    "LTRs = [rec for rec in SeqIO.parse(\"/var/tmp/xhorvat9/ltr_bert/FASTA_files/train_LTRs.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "n_sequences = len(LTRs)\n",
    "\n",
    "generated, genomic, markov = int(n_sequences*0.2), int(n_sequences*0.5), int(n_sequences*0.3)\n",
    "\n",
    "genomic_non_LTRs = [rec for rec in SeqIO.parse(\"/var/tmp/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_genomic_extracts.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if genomic < len(genomic_non_LTRs):\n",
    "    genomic_non_LTRs = random.sample(genomic_non_LTRs, genomic)\n",
    "generated_non_LTRs = [rec for rec in SeqIO.parse(\"/var/tmp/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_generated.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if generated < len(generated_non_LTRs):\n",
    "    generated_non_LTRs = random.sample(generated_non_LTRs, generated)\n",
    "markov_non_LTRs = [rec for rec in SeqIO.parse(\"/var/tmp/xhorvat9/ltr_bert/FASTA_files/non_LTRs_training_markovChain.fasta\", \"fasta\") if len(rec.seq) < MAX_LEN and len(rec.seq) > MIN_LEN]\n",
    "if markov < len(markov_non_LTRs):\n",
    "    markov_non_LTRs = random.sample(markov_non_LTRs, markov)\n",
    "non_LTRs = genomic_non_LTRs + generated_non_LTRs + markov_non_LTRs\n",
    "# test for sequences below 500\n",
    "sequences = [onehote(remove_N(str(rec.seq))) for rec in tqdm.tqdm(non_LTRs+LTRs)]\n",
    "#sequences = [onehote(str(rec.seq)) for rec in tqdm.tqdm(LTRs)] + [onehote(str(rec.seq)) for rec in tqdm.tqdm(non_LTRs)]\n",
    "labels = [0]*len(non_LTRs) + [1]*len(LTRs)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split into train and test\n",
    "paddedDNA = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"pre\", maxlen=MAX_LEN)\n",
    "trainX, valX, trainY, valY = train_test_split(paddedDNA, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv1D(filters=32, kernel_size=16, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model2.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model2.add(MaxPooling1D(pool_size=4))\n",
    "model2.add(LSTM(100))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'], weighted_metrics=[\"binary_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model2.fit(trainX, np.array(trainY), epochs=15, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "#model2.save(\"medium_seq_cnn_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/xhorvat9/tf_CUDA/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"all_length_cnn_lstm_for_SHAP.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3760/3760 [==============================] - 110s 29ms/step - loss: 0.5731 - binary_accuracy: 0.6839 - weighted_binary_accuracy: 0.6839 - val_loss: 0.5061 - val_binary_accuracy: 0.7461 - val_weighted_binary_accuracy: 0.7461\n",
      "Epoch 2/15\n",
      "3760/3760 [==============================] - 106s 28ms/step - loss: 0.4278 - binary_accuracy: 0.7946 - weighted_binary_accuracy: 0.7946 - val_loss: 0.3878 - val_binary_accuracy: 0.8175 - val_weighted_binary_accuracy: 0.8175\n",
      "Epoch 3/15\n",
      "3760/3760 [==============================] - 106s 28ms/step - loss: 0.3764 - binary_accuracy: 0.8243 - weighted_binary_accuracy: 0.8243 - val_loss: 0.3766 - val_binary_accuracy: 0.8240 - val_weighted_binary_accuracy: 0.8240\n",
      "Epoch 4/15\n",
      "3760/3760 [==============================] - 107s 28ms/step - loss: 0.3472 - binary_accuracy: 0.8406 - weighted_binary_accuracy: 0.8406 - val_loss: 0.3339 - val_binary_accuracy: 0.8474 - val_weighted_binary_accuracy: 0.8474\n",
      "Epoch 5/15\n",
      "3760/3760 [==============================] - 107s 28ms/step - loss: 0.3272 - binary_accuracy: 0.8516 - weighted_binary_accuracy: 0.8516 - val_loss: 0.3277 - val_binary_accuracy: 0.8523 - val_weighted_binary_accuracy: 0.8523\n",
      "Epoch 6/15\n",
      "3760/3760 [==============================] - 106s 28ms/step - loss: 0.3127 - binary_accuracy: 0.8595 - weighted_binary_accuracy: 0.8595 - val_loss: 0.3315 - val_binary_accuracy: 0.8535 - val_weighted_binary_accuracy: 0.8535\n",
      "Epoch 7/15\n",
      "3760/3760 [==============================] - 106s 28ms/step - loss: 0.2996 - binary_accuracy: 0.8670 - weighted_binary_accuracy: 0.8670 - val_loss: 0.2974 - val_binary_accuracy: 0.8680 - val_weighted_binary_accuracy: 0.8680\n",
      "Epoch 8/15\n",
      "3760/3760 [==============================] - 107s 28ms/step - loss: 0.2893 - binary_accuracy: 0.8715 - weighted_binary_accuracy: 0.8715 - val_loss: 0.3021 - val_binary_accuracy: 0.8648 - val_weighted_binary_accuracy: 0.8648\n",
      "Epoch 9/15\n",
      "3760/3760 [==============================] - 108s 29ms/step - loss: 0.2795 - binary_accuracy: 0.8757 - weighted_binary_accuracy: 0.8757 - val_loss: 0.3068 - val_binary_accuracy: 0.8621 - val_weighted_binary_accuracy: 0.8621\n",
      "Epoch 10/15\n",
      "3760/3760 [==============================] - 107s 28ms/step - loss: 0.2718 - binary_accuracy: 0.8804 - weighted_binary_accuracy: 0.8804 - val_loss: 0.3127 - val_binary_accuracy: 0.8606 - val_weighted_binary_accuracy: 0.8606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5f99241400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv1D(filters=128, kernel_size=16, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model3.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model3.add(MaxPooling1D(pool_size=4))\n",
    "model3.add(LSTM(100))\n",
    "model3.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'], weighted_metrics=[\"binary_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model3.fit(trainX, np.array(trainY), epochs=15, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "#model2.save(\"medium_seq_cnn_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3760/3760 [==============================] - 48s 12ms/step - loss: 0.4956 - binary_accuracy: 0.7467 - weighted_binary_accuracy: 0.7467 - val_loss: 0.4205 - val_binary_accuracy: 0.7991 - val_weighted_binary_accuracy: 0.7991\n",
      "Epoch 2/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.3937 - binary_accuracy: 0.8144 - weighted_binary_accuracy: 0.8144 - val_loss: 0.3836 - val_binary_accuracy: 0.8226 - val_weighted_binary_accuracy: 0.8226\n",
      "Epoch 3/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.3593 - binary_accuracy: 0.8345 - weighted_binary_accuracy: 0.8345 - val_loss: 0.3938 - val_binary_accuracy: 0.8163 - val_weighted_binary_accuracy: 0.8163\n",
      "Epoch 4/15\n",
      "3760/3760 [==============================] - 46s 12ms/step - loss: 0.3369 - binary_accuracy: 0.8470 - weighted_binary_accuracy: 0.8470 - val_loss: 0.3704 - val_binary_accuracy: 0.8252 - val_weighted_binary_accuracy: 0.8252\n",
      "Epoch 5/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.3209 - binary_accuracy: 0.8552 - weighted_binary_accuracy: 0.8552 - val_loss: 0.3289 - val_binary_accuracy: 0.8530 - val_weighted_binary_accuracy: 0.8530\n",
      "Epoch 6/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.3104 - binary_accuracy: 0.8605 - weighted_binary_accuracy: 0.8605 - val_loss: 0.3278 - val_binary_accuracy: 0.8512 - val_weighted_binary_accuracy: 0.8512\n",
      "Epoch 7/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.3006 - binary_accuracy: 0.8663 - weighted_binary_accuracy: 0.8663 - val_loss: 0.3042 - val_binary_accuracy: 0.8648 - val_weighted_binary_accuracy: 0.8648\n",
      "Epoch 8/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.2933 - binary_accuracy: 0.8690 - weighted_binary_accuracy: 0.8690 - val_loss: 0.3185 - val_binary_accuracy: 0.8585 - val_weighted_binary_accuracy: 0.8585\n",
      "Epoch 9/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.2871 - binary_accuracy: 0.8730 - weighted_binary_accuracy: 0.8730 - val_loss: 0.3168 - val_binary_accuracy: 0.8574 - val_weighted_binary_accuracy: 0.8574\n",
      "Epoch 10/15\n",
      "3760/3760 [==============================] - 45s 12ms/step - loss: 0.2803 - binary_accuracy: 0.8755 - weighted_binary_accuracy: 0.8755 - val_loss: 0.3197 - val_binary_accuracy: 0.8564 - val_weighted_binary_accuracy: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5f9907a2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv1D(filters=128, kernel_size=16, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model3.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model3.add(MaxPooling1D(pool_size=4))\n",
    "model3.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu', input_shape=trainX[0].shape))\n",
    "model3.add(Dropout(0.2))  # You can adjust the dropout rate as needed\n",
    "model3.add(MaxPooling1D(pool_size=4))\n",
    "model3.add(LSTM(100))\n",
    "model3.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'], weighted_metrics=[\"binary_accuracy\"])\n",
    "\n",
    "#model2.fit(valX, np.array(valY), epochs=3, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[WandbCallback()])\n",
    "model3.fit(trainX, np.array(trainY), epochs=15, batch_size=64,verbose = 1,validation_data=(valX, np.array(valY)), callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "#model2.save(\"medium_seq_cnn_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
